Tasks:
• Minimal Vulkan API reference: https://github.com/NVIDIAGameWorks/nvrhi

• Get rid of RenderPassDatabase
    • dynamic_cast is not allowed in most AAA game engines
    • It's linearly iterating through all Renderers & dynamic casting, which is bad for perf
    • It's also not necessary. Just declare a Renderer in Global scope in its own .cpp file, and extern the GfxRenderpass ptr in VulkanRenderer.

• Remove all forms of stalling from the pipeline
	• Debug why GpuVector::writeTo is always reserving

• Remove all forms of binary semaphores
	• Implement a frame counter and semaphore signal at end of present

• Implement frame based deleter
	• Use VK_SEMAPHORE_TYPE_TIMELINE counting semaphore to check frame on GPU

• Change to from renderpasses to VK_KHR_dynamic_rendering

• Only support 1 Camera

• Proper Frame Fencing
    • Should only stall CPU before the FIRST command buffer submission

• Support only 1 queue for now
	• Remove transfer queue

• GBuffer Render Targets:
    • Normal should be R10G10B10A2
    • Don't store Entity ID as GBuffer RT
    • Emissive should be RGBA8
        • Optimization opportunity: Separate render pass for objects that have emissive, which should not be alot

• IBL rendering
    • Directional light
    • Scene cube map
    • Sky dome
    • Once implemented, remove gbuffer albedo clear

• True HDR pipeline
    • Luminance Histogram generation
    • Attenuate scene color based on scene luminance (eye adaptation)

• HDR Render Targets:
	• Should be R10G10B11
	• Should return to RGBA8 after tonemapping

• GPU-driven renderer
    • Implement this Step-by-Step. This is a huge & complex undertaking with multiple chained indirect dispatches
    • 1st Evolution: Batch & dispatch draw calls on CPU first
        • Since you already have virtual vertex & index buffers, and bindless textures, you only need to batch by Mesh
    • 2nd evolution: occlusion cull batches (ZPrePass needed)
        • Increment instance count if not culled, and append instance data to external buffer
        • DispatchIndirect using InstanceCount buffer as draw parameter buffer
        • BONUS: Compact buffer to get rid of empty draw calls (put a wall in between all meshes to test)
        • Will still require 1 DispatchIndirect per mesh batch
    • 3rd evolution: Generate batches on GPU
        • Upload all CPU-culled instance data in a linear buffer to culling CS 
            • All batches in one go
        • Build batches in CS. Internally "bucketize" batches in external linear buffer, generate appropriate offsets to external buffers
        • If done properly, 1 DispatchIndirect for whole scene
            • Only because everything uses the same uber GBuffer Shader, else its 1 DispatchIndirect per Shader

• Separate GBuffer draw call specifically for skinned meshes
    • Can (should) be run in parallel in another thread & Renderer
    • dont mix with static non-skinned meshes
    • the 'skinned' bool should not be information from the instance
        • it shouldbe from a constant buffer, like say, a PassContext UBO
        • Best if it's a separate Shader Permutation

• Automatic texture mip generation on GPU
    • Utilize this if you want: https://github.com/GPUOpen-LibrariesAndSDKs/FidelityFX-SDK/blob/main/docs/techniques/single-pass-downsampler.md
    • Use anisotropic sampler

• Generate shadow mask in a seperate PS
    • deferred lighting pass should not compute shadows, only sample shadow mask texture

• Oct-tree culling on CPU
    • Practically mandatory. Uploading the entire scene's worth of instance transforms every frame cannot scale up.
    • Same for Directional Light Shadow pass
    • Cull objects ONCE per view-proj (Should only be 2. Camera & Dir Light), then re-use culled lists of objects in all Renderers

• Tile-based Deferred Rendering
    • Support point lights only for now
    • Classify tiles on screen based on complexity
        • nb local lights
        • material complexity?
    • Generate screen-space grid, using grid index as index to lights buffer
    • Dispatch draw calls on screen via DrawIndirect. Build tile screen positions & offsets in separate CS

• Use giant GPU circular buffers for gpu instance transforms
    • Suballocate exact necessary bytes as neededed for culled instances
    • Pass buffer offset to VS

• Don't clear GBuffer every frame
    • Your game should have every pixel in every GBuffer Render Target filled up.

• Encapsulate as many Vulkan API calls as possible inside your "CommandList" class

• Implement Full Z-PrePass
    • Treat every Opaque object as an occluder to keep things simple

• Multi-thread all Graphic Tasks & Renderers
    • Implement free-list of command buffers. They must all be properly fenced before re-used

• Render Graph
    • Scheduling of asynchronous compute fences
    • Allocation of transient resources with optimal lifetimes and memory aliasing
    • Transitioning of sub-resources using split-barriers to hide latency and improve overlap on the GPU
    • Parallel command list recording
    • Culling of unused resources and passes in the graph
    • Validation of usage and resource dependencies

• Compute Queue
    • Anything that can be run asyncronously with Graphics Queue, should
    • GPU Fence where necessary

• Vulkan Memory Allocator: https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator

• AMD ShadowFX: https://github.com/GPUOpen-Effects/ShadowFX
    
• AMD Combined Adaptive Compute Ambient Occlusion (CACAO):  https://github.com/GPUOpen-LibrariesAndSDKs/FidelityFX-SDK/blob/main/docs/techniques/combined-adaptive-compute-ambient-occlusion.md

• AMD Stochastic Screen-Space Reflections: https://github.com/GPUOpen-LibrariesAndSDKs/FidelityFX-SDK/blob/main/docs/techniques/stochastic-screen-space-reflections.md

• AMD FSR 2.0: https://github.com/GPUOpen-LibrariesAndSDKs/FidelityFX-SDK/blob/main/docs/techniques/super-resolution-temporal.md
